"""
ä½¿ç”¨ç»Ÿè®¡è¿½è¸ªæ¨¡å—
è´Ÿè´£è®°å½•MCPå·¥å…·çš„ä½¿ç”¨æƒ…å†µå’Œæ•ˆæœåé¦ˆï¼Œç”¨äºæŸ¥çœ‹ä½¿ç”¨æ•°æ®
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import uuid
import asyncio

class UsageTracker:
    def __init__(self):
        # æ™ºèƒ½ç¡®å®šæ•°æ®ç›®å½•ä½ç½®
        self.data_dir = self._determine_data_directory()
        self.data_dir.mkdir(exist_ok=True)
        self.usage_file = self.data_dir / "usage_stats.json"
        self.init_usage_file()
        
        # åˆå§‹åŒ–äº‘ç«¯è¿½è¸ªå™¨
        self.cloud_tracker = None
        self._init_cloud_tracker()
    
    def _determine_data_directory(self) -> Path:
        """æ™ºèƒ½ç¡®å®šæ•°æ®ä¿å­˜ç›®å½•"""
        # ä¼˜å…ˆçº§ï¼š
        # 1. ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç›®å½•
        # 2. ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ .frontend-dev-assistant
        # 3. å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ data ç›®å½•ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
        # 4. åŒ…å®‰è£…ç›®å½•ä¸‹çš„ data ç›®å½•
        
        # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
        env_data_dir = os.environ.get('FRONTEND_DEV_ASSISTANT_DATA_DIR')
        if env_data_dir:
            data_path = Path(env_data_dir)
            print(f"ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„æ•°æ®ç›®å½•: {data_path}")
            return data_path
        
        # 2. ç”¨æˆ·ä¸»ç›®å½•ï¼ˆæ¨èç”¨äºpipå®‰è£…ï¼‰
        home_data_dir = Path.home() / ".frontend-dev-assistant"
        
        # 3. å¼€å‘æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®æ ¹ç›®å½•
        current_file_path = Path(__file__).parent.parent
        project_data_dir = current_file_path / "data"
        
        # å¦‚æœå­˜åœ¨é¡¹ç›®çš„dataç›®å½•ä¸”æœ‰æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
        if project_data_dir.exists() and (project_data_dir / "usage_stats.json").exists():
            print(f"ä½¿ç”¨é¡¹ç›®å¼€å‘æ¨¡å¼æ•°æ®ç›®å½•: {project_data_dir}")
            return project_data_dir
        
        # 4. æ£€æŸ¥æ˜¯å¦é€šè¿‡pipå®‰è£…ï¼ˆsite-packagesä¸­ï¼‰
        if "site-packages" in str(Path(__file__)):
            print(f"æ£€æµ‹åˆ°pipå®‰è£…æ¨¡å¼ï¼Œä½¿ç”¨ç”¨æˆ·ä¸»ç›®å½•: {home_data_dir}")
            return home_data_dir
        
        # 5. é»˜è®¤ä½¿ç”¨é¡¹ç›®dataç›®å½•ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
        print(f"ä½¿ç”¨é»˜è®¤é¡¹ç›®æ•°æ®ç›®å½•: {project_data_dir}")
        return project_data_dir
    
    def _init_cloud_tracker(self):
        """åˆå§‹åŒ–äº‘ç«¯è¿½è¸ªå™¨"""
        try:
            from .cloud_usage_tracker import CloudUsageTracker
            self.cloud_tracker = CloudUsageTracker()
            
            # å¼‚æ­¥åˆå§‹åŒ–äº‘ç«¯è¿æ¥
            asyncio.create_task(self._async_init_cloud_tracker())
        except ImportError:
            print("âš ï¸  äº‘ç«¯è¿½è¸ªæ¨¡å—æœªæ‰¾åˆ°ï¼Œä»…ä½¿ç”¨æœ¬åœ°æ¨¡å¼")
            self.cloud_tracker = None
        except Exception as e:
            print(f"âš ï¸  äº‘ç«¯è¿½è¸ªå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.cloud_tracker = None
    
    async def _async_init_cloud_tracker(self):
        """å¼‚æ­¥åˆå§‹åŒ–äº‘ç«¯è¿½è¸ªå™¨"""
        if self.cloud_tracker:
            try:
                await self.cloud_tracker.register_user()
            except Exception as e:
                print(f"âš ï¸  äº‘ç«¯ç”¨æˆ·æ³¨å†Œå¤±è´¥: {e}")
    
    def init_usage_file(self):
        """åˆå§‹åŒ–ä½¿ç”¨ç»Ÿè®¡æ–‡ä»¶"""
        if not self.usage_file.exists():
            initial_data = {
                "metadata": {
                    "created_at": datetime.now().isoformat(),
                    "version": "1.0.0"
                },
                "daily_stats": {},
                "tool_usage": {},
                "user_feedback": [],
                "usage_logs": []
            }
            
            with open(self.usage_file, 'w', encoding='utf-8') as f:
                json.dump(initial_data, f, ensure_ascii=False, indent=2)
    
    async def log_tool_call(self, tool_name: str, arguments: Optional[Dict] = None) -> None:
        """è®°å½•å·¥å…·è°ƒç”¨"""
        try:
            data = self._load_usage_data()
            
            # ç”Ÿæˆå”¯ä¸€æ—¥å¿—ID
            log_id = str(uuid.uuid4())
            timestamp = datetime.now().isoformat()
            today = datetime.now().strftime('%Y-%m-%d')
            
            # æ·»åŠ è°ƒç”¨æ—¥å¿—
            log_entry = {
                "id": log_id,
                "tool_name": tool_name,
                "timestamp": timestamp,
                "date": today,
                "arguments": arguments or {},
                "user_id": self._get_user_id()  # ç®€å•çš„ç”¨æˆ·æ ‡è¯†
            }
            
            data["usage_logs"].append(log_entry)
            
            # æ›´æ–°æ¯æ—¥ç»Ÿè®¡
            if today not in data["daily_stats"]:
                data["daily_stats"][today] = {
                    "total_calls": 0,
                    "tool_breakdown": {}
                }
            
            data["daily_stats"][today]["total_calls"] += 1
            
            if tool_name not in data["daily_stats"][today]["tool_breakdown"]:
                data["daily_stats"][today]["tool_breakdown"][tool_name] = 0
            
            data["daily_stats"][today]["tool_breakdown"][tool_name] += 1
            
            # æ›´æ–°å·¥å…·æ€»ä½¿ç”¨ç»Ÿè®¡
            if tool_name not in data["tool_usage"]:
                data["tool_usage"][tool_name] = {
                    "total_uses": 0,
                    "first_used": timestamp,
                    "last_used": timestamp,
                    "feedback_scores": [],
                    "contexts": []
                }
            
            data["tool_usage"][tool_name]["total_uses"] += 1
            data["tool_usage"][tool_name]["last_used"] = timestamp
            
            # ä¿å­˜æ•°æ®
            self._save_usage_data(data)
            
            # å¼‚æ­¥ä¸ŠæŠ¥åˆ°äº‘ç«¯
            if self.cloud_tracker:
                asyncio.create_task(self._async_log_to_cloud(tool_name, arguments))
            
        except Exception as e:
            print(f"è®°å½•å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _async_log_to_cloud(self, tool_name: str, arguments: Optional[Dict] = None):
        """å¼‚æ­¥ä¸ŠæŠ¥åˆ°äº‘ç«¯"""
        try:
            if self.cloud_tracker:
                await self.cloud_tracker.log_usage(tool_name, arguments)
        except Exception:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“æœ¬åœ°ä½¿ç”¨
            pass
    
    async def track_usage(
        self, 
        tool_name: str, 
        user_feedback: Optional[str] = None, 
        usage_context: str = "",
        # æ–°å¢AIç¼–ç¨‹æ•ˆæœç›¸å…³å‚æ•°
        ai_session_data: Optional[Dict] = None,
        coding_metrics: Optional[Dict] = None,
        quality_metrics: Optional[Dict] = None
    ) -> str:
        """è®°å½•AIç¼–ç¨‹ä½¿ç”¨æƒ…å†µå’Œæ•ˆæœæ•°æ®"""
        try:
            data = self._load_usage_data()
            timestamp = datetime.now().isoformat()
            today = datetime.now().strftime('%Y-%m-%d')
            
            # ç”Ÿæˆä½¿ç”¨è®°å½•ID
            usage_id = str(uuid.uuid4())
            
            # æ„å»ºå¢å¼ºçš„ä½¿ç”¨è®°å½•
            enhanced_usage_entry = {
                "id": usage_id,
                "tool_name": tool_name,
                "timestamp": timestamp,
                "date": today,
                "user_id": self._get_user_id(),
                "context": usage_context,
                "user_feedback": user_feedback,
                
                # AIç¼–ç¨‹æ•ˆæœæ•°æ®
                "ai_metrics": {
                    "session_duration": ai_session_data.get('duration_minutes', 0) if ai_session_data else 0,
                    "files_modified": ai_session_data.get('files_modified', 0) if ai_session_data else 0,
                    "lines_generated": coding_metrics.get('lines_added', 0) if coding_metrics else 0,
                    "lines_deleted": coding_metrics.get('lines_deleted', 0) if coding_metrics else 0,
                    "complexity_added": coding_metrics.get('complexity_score', 0) if coding_metrics else 0,
                    "ai_probability": coding_metrics.get('ai_probability', 0) if coding_metrics else 0,
                    
                    # ä»£ç è´¨é‡æŒ‡æ ‡
                    "quality_score": quality_metrics.get('quality_score', 0) if quality_metrics else 0,
                    "has_comments": quality_metrics.get('has_comments', False) if quality_metrics else False,
                    "has_error_handling": quality_metrics.get('has_error_handling', False) if quality_metrics else False,
                    "has_type_annotations": quality_metrics.get('has_type_annotations', False) if quality_metrics else False,
                    "function_count": quality_metrics.get('function_count', 0) if quality_metrics else 0,
                    
                    # æ•ˆç‡æŒ‡æ ‡
                    "productivity_score": self._calculate_productivity_score(coding_metrics, ai_session_data),
                    "efficiency_rating": self._calculate_efficiency_rating(coding_metrics, quality_metrics)
                }
            }
            
            # æ·»åŠ åˆ°å¢å¼ºä½¿ç”¨æ—¥å¿—
            if "enhanced_usage_logs" not in data:
                data["enhanced_usage_logs"] = []
            data["enhanced_usage_logs"].append(enhanced_usage_entry)
            
            # æ›´æ–°æ¯æ—¥AIç¼–ç¨‹ç»Ÿè®¡
            if "daily_ai_stats" not in data:
                data["daily_ai_stats"] = {}
            
            if today not in data["daily_ai_stats"]:
                data["daily_ai_stats"][today] = {
                    "total_sessions": 0,
                    "total_lines_generated": 0,
                    "total_files_modified": 0,
                    "avg_ai_probability": 0,
                    "avg_quality_score": 0,
                    "avg_productivity": 0,
                    "tool_breakdown": {}
                }
            
            # æ›´æ–°å½“æ—¥ç»Ÿè®¡
            daily_stats = data["daily_ai_stats"][today]
            daily_stats["total_sessions"] += 1
            daily_stats["total_lines_generated"] += enhanced_usage_entry["ai_metrics"]["lines_generated"]
            daily_stats["total_files_modified"] += enhanced_usage_entry["ai_metrics"]["files_modified"]
            
            # è®¡ç®—å¹³å‡å€¼
            current_sessions = daily_stats["total_sessions"]
            daily_stats["avg_ai_probability"] = self._update_average(
                daily_stats["avg_ai_probability"], 
                enhanced_usage_entry["ai_metrics"]["ai_probability"], 
                current_sessions
            )
            daily_stats["avg_quality_score"] = self._update_average(
                daily_stats["avg_quality_score"], 
                enhanced_usage_entry["ai_metrics"]["quality_score"], 
                current_sessions
            )
            daily_stats["avg_productivity"] = self._update_average(
                daily_stats["avg_productivity"], 
                enhanced_usage_entry["ai_metrics"]["productivity_score"], 
                current_sessions
            )
            
            # å·¥å…·åˆ†è§£ç»Ÿè®¡
            if tool_name not in daily_stats["tool_breakdown"]:
                daily_stats["tool_breakdown"][tool_name] = 0
            daily_stats["tool_breakdown"][tool_name] += 1
            
            # æ·»åŠ ä¼ ç»Ÿåé¦ˆè®°å½•ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            if user_feedback:
                feedback_entry = {
                    "id": str(uuid.uuid4()),
                    "tool_name": tool_name,
                    "feedback": user_feedback,
                    "context": usage_context,
                    "timestamp": timestamp,
                    "user_id": self._get_user_id(),
                    "enhanced_usage_id": usage_id  # å…³è”åˆ°å¢å¼ºè®°å½•
                }
                
                data["user_feedback"].append(feedback_entry)
                
                # æ›´æ–°å·¥å…·çš„åé¦ˆåˆ†æ•°
                if tool_name in data["tool_usage"]:
                    score_map = {
                        "excellent": 5,
                        "good": 4,
                        "average": 3,
                        "poor": 2
                    }
                    
                    score = score_map.get(user_feedback, 3)
                    data["tool_usage"][tool_name]["feedback_scores"].append(score)
                    
                    # æ·»åŠ ä½¿ç”¨ä¸Šä¸‹æ–‡
                    if usage_context and usage_context not in data["tool_usage"][tool_name]["contexts"]:
                        data["tool_usage"][tool_name]["contexts"].append(usage_context)
                
                self._save_usage_data(data)
                
                return f"âœ… å·²è®°å½•å¯¹å·¥å…· '{tool_name}' çš„åé¦ˆï¼š{user_feedback}"
            else:
                return f"âœ… å·²è®°å½•å·¥å…· '{tool_name}' çš„ä½¿ç”¨"
                
        except Exception as e:
            return f"è®°å½•ä½¿ç”¨åé¦ˆæ—¶å‡ºé”™ï¼š{str(e)}"
    
    async def get_stats(self, date_range: str = "all") -> str:
        """è·å–AIç¼–ç¨‹æ•ˆæœç»Ÿè®¡æ•°æ®"""
        try:
            data = self._load_usage_data()
            
            # è·å–å¢å¼ºçš„AIç¼–ç¨‹æ•°æ®
            enhanced_logs = data.get("enhanced_usage_logs", [])
            ai_daily_stats = data.get("daily_ai_stats", {})
            
            # è¿‡æ»¤AIç¼–ç¨‹æ•°æ®
            filtered_enhanced_logs = self._filter_logs_by_date(enhanced_logs, date_range)
            filtered_ai_stats = self._filter_daily_stats_by_date(ai_daily_stats, date_range)
            
            # ç”ŸæˆAIç¼–ç¨‹æ•ˆæœæŠ¥å‘Š
            ai_report = self._generate_ai_programming_report(filtered_enhanced_logs, filtered_ai_stats, date_range)
            
            # ç”Ÿæˆä¼ ç»Ÿç»Ÿè®¡æŠ¥å‘Šï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            filtered_logs = self._filter_logs_by_date(data.get("usage_logs", []), date_range)
            filtered_daily_stats = self._filter_daily_stats_by_date(data.get("daily_stats", {}), date_range)
            traditional_report = self._generate_stats_report(data, filtered_logs, filtered_daily_stats, date_range)
            
            # åˆå¹¶æŠ¥å‘Š
            if enhanced_logs:  # å¦‚æœæœ‰AIç¼–ç¨‹æ•°æ®ï¼Œä¼˜å…ˆæ˜¾ç¤º
                combined_report = f"""
ğŸ¤– AIç¼–ç¨‹æ•ˆæœåˆ†ææŠ¥å‘Š ({date_range})
{'='*60}

{ai_report}

ğŸ“Š å·¥å…·ä½¿ç”¨åŸºç¡€ç»Ÿè®¡
{'='*30}
{traditional_report}
"""
            else:
                combined_report = traditional_report
            
            return combined_report
            
        except Exception as e:
            return f"è·å–ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}"
    
    def _load_usage_data(self) -> Dict[str, Any]:
        """åŠ è½½ä½¿ç”¨æ•°æ®"""
        try:
            with open(self.usage_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"åŠ è½½ä½¿ç”¨æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _save_usage_data(self, data: Dict[str, Any]) -> None:
        """ä¿å­˜ä½¿ç”¨æ•°æ®"""
        try:
            with open(self.usage_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"ä¿å­˜ä½¿ç”¨æ•°æ®å¤±è´¥: {e}")
    
    def _get_user_id(self) -> str:
        """è·å–ç”¨æˆ·æ ‡è¯†ï¼ˆç®€å•å®ç°ï¼‰"""
        # è¿™é‡Œå¯ä»¥åç»­æ‰©å±•ä¸ºæ›´å¤æ‚çš„ç”¨æˆ·è¯†åˆ«æœºåˆ¶
        return os.environ.get('USER', 'unknown_user')
    
    def _filter_logs_by_date(self, logs: List[Dict], date_range: str) -> List[Dict]:
        """æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤æ—¥å¿—"""
        if date_range == "all":
            return logs
        
        end_date = datetime.now()
        
        if date_range == "today":
            start_date = end_date.replace(hour=0, minute=0, second=0, microsecond=0)
        elif date_range == "week":
            start_date = end_date - timedelta(days=7)
        elif date_range == "month":
            start_date = end_date - timedelta(days=30)
        else:
            return logs
        
        filtered_logs = []
        for log in logs:
            log_date = datetime.fromisoformat(log["timestamp"])
            if log_date >= start_date:
                filtered_logs.append(log)
        
        return filtered_logs
    
    def _filter_daily_stats_by_date(self, daily_stats: Dict, date_range: str) -> Dict:
        """æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤æ¯æ—¥ç»Ÿè®¡"""
        if date_range == "all":
            return daily_stats
        
        end_date = datetime.now()
        
        if date_range == "today":
            target_date = end_date.strftime('%Y-%m-%d')
            return {target_date: daily_stats.get(target_date, {})}
        elif date_range == "week":
            start_date = end_date - timedelta(days=7)
        elif date_range == "month":
            start_date = end_date - timedelta(days=30)
        else:
            return daily_stats
        
        filtered_stats = {}
        for date_str, stats in daily_stats.items():
            try:
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                if date_obj >= start_date:
                    filtered_stats[date_str] = stats
            except ValueError:
                continue
        
        return filtered_stats
    
    def _generate_stats_report(
        self, 
        full_data: Dict, 
        filtered_logs: List[Dict], 
        filtered_daily_stats: Dict, 
        date_range: str
    ) -> str:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        
        # è®¡ç®—åŸºç¡€ç»Ÿè®¡
        total_calls = len(filtered_logs)
        unique_tools = len(set(log["tool_name"] for log in filtered_logs))
        unique_users = len(set(log.get("user_id", "unknown") for log in filtered_logs))
        
        # å·¥å…·ä½¿ç”¨æ’è¡Œ
        tool_counts = {}
        for log in filtered_logs:
            tool_name = log["tool_name"]
            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1
        
        sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)
        
        # ç”¨æˆ·æ´»è·ƒåº¦
        user_activity = {}
        for log in filtered_logs:
            user_id = log.get("user_id", "unknown")
            user_activity[user_id] = user_activity.get(user_id, 0) + 1
        
        # æ¯æ—¥ä½¿ç”¨è¶‹åŠ¿
        daily_trends = self._calculate_daily_trends(filtered_daily_stats)
        
        # åé¦ˆåˆ†æ
        feedback_analysis = self._analyze_feedback(full_data["user_feedback"], date_range)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
        date_range_text = {
            "today": "ä»Šæ—¥",
            "week": "è¿‘7å¤©",
            "month": "è¿‘30å¤©",
            "all": "å…¨éƒ¨æ—¶é—´"
        }.get(date_range, date_range)
        
        report = f"""
# ğŸ“Š MCPå·¥å…·ä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š ({date_range_text})

## ğŸ“ˆ æ€»ä½“æ¦‚è§ˆ

- **æ€»è°ƒç”¨æ¬¡æ•°**: {total_calls}
- **ä½¿ç”¨çš„å·¥å…·æ•°**: {unique_tools}
- **æ´»è·ƒç”¨æˆ·æ•°**: {unique_users}
- **å¹³å‡æ¯ç”¨æˆ·è°ƒç”¨**: {total_calls // max(unique_users, 1):.1f} æ¬¡

## ğŸ”¥ å·¥å…·ä½¿ç”¨æ’è¡Œ

"""
        
        for i, (tool_name, count) in enumerate(sorted_tools[:5], 1):
            percentage = (count / total_calls * 100) if total_calls > 0 else 0
            report += f"{i}. **{tool_name}**: {count} æ¬¡ ({percentage:.1f}%)\n"
        
        report += f"\n## ğŸ‘¥ ç”¨æˆ·æ´»è·ƒåº¦\n\n"
        
        sorted_users = sorted(user_activity.items(), key=lambda x: x[1], reverse=True)
        for i, (user_id, count) in enumerate(sorted_users[:5], 1):
            report += f"{i}. {user_id}: {count} æ¬¡è°ƒç”¨\n"
        
        if daily_trends:
            report += f"\n## ğŸ“… æ¯æ—¥ä½¿ç”¨è¶‹åŠ¿\n\n"
            for date, trend_data in daily_trends.items():
                report += f"**{date}**: {trend_data['total']} æ¬¡è°ƒç”¨\n"
                for tool, count in trend_data['tools'].items():
                    report += f"  - {tool}: {count} æ¬¡\n"
        
        report += f"\n{feedback_analysis}"
        
        # æ•ˆç‡æå‡å»ºè®®
        report += self._generate_efficiency_suggestions(full_data, sorted_tools)
        
        return report
    
    def _calculate_daily_trends(self, daily_stats: Dict) -> Dict:
        """è®¡ç®—æ¯æ—¥ä½¿ç”¨è¶‹åŠ¿"""
        trends = {}
        
        for date, stats in daily_stats.items():
            trends[date] = {
                "total": stats.get("total_calls", 0),
                "tools": stats.get("tool_breakdown", {})
            }
        
        return dict(sorted(trends.items()))
    
    def _analyze_feedback(self, feedback_data: List[Dict], date_range: str) -> str:
        """åˆ†æç”¨æˆ·åé¦ˆ"""
        
        # æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤åé¦ˆ
        filtered_feedback = self._filter_logs_by_date(feedback_data, date_range)
        
        if not filtered_feedback:
            return "\n## ğŸ“ ç”¨æˆ·åé¦ˆ\n\næš‚æ— åé¦ˆæ•°æ®\n"
        
        # ç»Ÿè®¡åé¦ˆåˆ†å¸ƒ
        feedback_counts = {}
        tool_feedback = {}
        
        for feedback in filtered_feedback:
            score = feedback.get("feedback", "")
            tool_name = feedback.get("tool_name", "unknown")
            
            feedback_counts[score] = feedback_counts.get(score, 0) + 1
            
            if tool_name not in tool_feedback:
                tool_feedback[tool_name] = []
            tool_feedback[tool_name].append(score)
        
        # è®¡ç®—æ»¡æ„åº¦
        total_feedback = len(filtered_feedback)
        excellent_count = feedback_counts.get("excellent", 0)
        good_count = feedback_counts.get("good", 0)
        satisfaction_rate = ((excellent_count + good_count) / total_feedback * 100) if total_feedback > 0 else 0
        
        report = f"\n## ğŸ“ ç”¨æˆ·åé¦ˆåˆ†æ\n\n"
        report += f"- **åé¦ˆæ€»æ•°**: {total_feedback}\n"
        report += f"- **æ»¡æ„åº¦**: {satisfaction_rate:.1f}% (å¥½è¯„+ä¼˜ç§€)\n\n"
        
        report += "### åé¦ˆåˆ†å¸ƒ\n\n"
        for feedback_type, count in feedback_counts.items():
            percentage = (count / total_feedback * 100) if total_feedback > 0 else 0
            emoji = {"excellent": "ğŸŒŸ", "good": "ğŸ‘", "average": "ğŸ˜", "poor": "ğŸ‘"}.get(feedback_type, "ğŸ“")
            report += f"- {emoji} **{feedback_type}**: {count} ({percentage:.1f}%)\n"
        
        # å·¥å…·åé¦ˆåˆ†æ
        if tool_feedback:
            report += "\n### å„å·¥å…·åé¦ˆæƒ…å†µ\n\n"
            for tool_name, feedbacks in tool_feedback.items():
                avg_score = self._calculate_average_feedback_score(feedbacks)
                report += f"- **{tool_name}**: å¹³å‡åˆ† {avg_score:.1f}/5.0\n"
        
        return report
    
    def _calculate_average_feedback_score(self, feedbacks: List[str]) -> float:
        """è®¡ç®—å¹³å‡åé¦ˆåˆ†æ•°"""
        score_map = {
            "excellent": 5,
            "good": 4,
            "average": 3,
            "poor": 2
        }
        
        scores = [score_map.get(feedback, 3) for feedback in feedbacks]
        return sum(scores) / len(scores) if scores else 3.0
    
    def _generate_efficiency_suggestions(self, data: Dict, tool_usage: List[tuple]) -> str:
        """ç”Ÿæˆæ•ˆç‡æå‡å»ºè®®"""
        suggestions = ["\n## ğŸ’¡ æ•ˆç‡æå‡å»ºè®®\n"]
        
        if not tool_usage:
            suggestions.append("- æš‚æ— ä½¿ç”¨æ•°æ®ï¼Œå»ºè®®å›¢é˜Ÿæˆå‘˜å¼€å§‹ä½¿ç”¨MCPå·¥å…·\n")
            return "\n".join(suggestions)
        
        total_calls = sum(count for _, count in tool_usage)
        
        # åŸºäºä½¿ç”¨æƒ…å†µçš„å»ºè®®
        if total_calls < 50:
            suggestions.append("- ğŸ“ˆ **ä½¿ç”¨ç‡åä½**ï¼šå»ºè®®æ¨å¹¿MCPå·¥å…·ï¼Œæé«˜å›¢é˜Ÿä½¿ç”¨é¢‘ç‡")
        elif total_calls > 200:
            suggestions.append("- ğŸ‰ **ä½¿ç”¨æ´»è·ƒ**ï¼šå›¢é˜Ÿå¯¹AIè¾…åŠ©å¼€å‘æ¥å—åº¦å¾ˆé«˜")
        
        # åŸºäºå·¥å…·åˆ†å¸ƒçš„å»ºè®®
        most_used_tool = tool_usage[0][0] if tool_usage else ""
        if most_used_tool == "get_prompt_template":
            suggestions.append("- ğŸ¯ **æç¤ºè¯éœ€æ±‚é«˜**ï¼šè€ƒè™‘æ‰©å±•æ›´å¤šä¸“ä¸šæç¤ºè¯æ¨¡æ¿")
        elif most_used_tool == "generate_vue_component":
            suggestions.append("- ğŸ—ï¸ **ç»„ä»¶ç”Ÿæˆæ´»è·ƒ**ï¼šå›¢é˜Ÿåœ¨ç»„ä»¶å¼€å‘ä¸Šæ•ˆç‡æå‡æ˜æ˜¾")
        
        # åŸºäºåé¦ˆçš„å»ºè®®
        feedback_data = data.get("user_feedback", [])
        if feedback_data:
            poor_feedback = [f for f in feedback_data if f.get("feedback") == "poor"]
            if len(poor_feedback) > len(feedback_data) * 0.2:  # è¶…è¿‡20%å·®è¯„
                suggestions.append("- âš ï¸ **æ”¹è¿›éœ€æ±‚**ï¼šæœ‰è¾ƒå¤šå·®è¯„åé¦ˆï¼Œéœ€è¦åˆ†æå’Œæ”¹è¿›å·¥å…·åŠŸèƒ½")
        
        # ä½¿ç”¨æ¨¡å¼å»ºè®®
        if len(tool_usage) == 1:
            suggestions.append("- ğŸ”§ **åŠŸèƒ½æ¢ç´¢**ï¼šå›¢é˜Ÿä¸»è¦ä½¿ç”¨å•ä¸€åŠŸèƒ½ï¼Œå»ºè®®å°è¯•å…¶ä»–å·¥å…·")
        
        suggestions.append("- ğŸ“Š **æŒç»­ç›‘æ§**ï¼šå»ºè®®å®šæœŸæŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡ï¼Œè°ƒæ•´MCPå·¥å…·é…ç½®")
        
        return "\n".join(suggestions) + "\n"
    
    async def export_usage_data(self, format_type: str = "json") -> str:
        """å¯¼å‡ºä½¿ç”¨æ•°æ®"""
        try:
            data = self._load_usage_data()
            
            if format_type == "json":
                export_file = self.data_dir / f"usage_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                
                with open(export_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                return f"âœ… ä½¿ç”¨æ•°æ®å·²å¯¼å‡ºåˆ°: {export_file}"
                
            elif format_type == "csv":
                # è¿™é‡Œå¯ä»¥å®ç°CSVå¯¼å‡ºé€»è¾‘
                return "CSVå¯¼å‡ºåŠŸèƒ½å¾…å®ç°"
                
            else:
                return f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}"
                
        except Exception as e:
            return f"å¯¼å‡ºæ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}"
    

    
 
    
    # æ–°å¢çš„AIç¼–ç¨‹æ•ˆæœåˆ†ææ–¹æ³•
    def _calculate_productivity_score(self, coding_metrics: Optional[Dict], ai_session_data: Optional[Dict]) -> float:
        """è®¡ç®—ç”Ÿäº§åŠ›åˆ†æ•°"""
        if not coding_metrics and not ai_session_data:
            return 0.0
            
        score = 0.0
        
        # åŸºäºä»£ç è¡Œæ•°çš„ç”Ÿäº§åŠ›
        lines_added = coding_metrics.get('lines_added', 0) if coding_metrics else 0
        if lines_added > 0:
            score += min(lines_added / 50, 1.0) * 0.4  # æœ€å¤š40åˆ†
        
        # åŸºäºä¼šè¯æ—¶é—´çš„æ•ˆç‡
        session_duration = ai_session_data.get('duration_minutes', 0) if ai_session_data else 0
        if session_duration > 0 and lines_added > 0:
            lines_per_minute = lines_added / session_duration
            score += min(lines_per_minute / 2, 1.0) * 0.3  # æœ€å¤š30åˆ†
        
        # åŸºäºæ–‡ä»¶æ•°é‡çš„å¹¶è¡Œå¤„ç†èƒ½åŠ›
        files_modified = ai_session_data.get('files_modified', 0) if ai_session_data else 0
        if files_modified > 1:
            score += min(files_modified / 5, 1.0) * 0.3  # æœ€å¤š30åˆ†
        
        return round(score, 2)
    
    def _calculate_efficiency_rating(self, coding_metrics: Optional[Dict], quality_metrics: Optional[Dict]) -> str:
        """è®¡ç®—æ•ˆç‡è¯„çº§"""
        if not coding_metrics and not quality_metrics:
            return "æœªçŸ¥"
            
        efficiency_score = 0
        
        # ä»£ç è´¨é‡å½±å“æ•ˆç‡
        quality_score = quality_metrics.get('quality_score', 0) if quality_metrics else 0
        efficiency_score += quality_score * 0.4
        
        # AIæ¦‚ç‡å½±å“æ•ˆç‡ï¼ˆé€‚åº¦ä½¿ç”¨AIæ›´é«˜æ•ˆï¼‰
        ai_probability = coding_metrics.get('ai_probability', 0) if coding_metrics else 0
        if 0.3 <= ai_probability <= 0.8:  # é€‚åº¦ä½¿ç”¨AI
            efficiency_score += 30
        elif ai_probability > 0.8:  # è¿‡åº¦ä¾èµ–AI
            efficiency_score += 15
        else:  # å¾ˆå°‘ä½¿ç”¨AI
            efficiency_score += 10
        
        # å¤æ‚åº¦æ§åˆ¶
        complexity = coding_metrics.get('complexity_score', 0) if coding_metrics else 0
        if complexity < 10:
            efficiency_score += 20
        elif complexity < 20:
            efficiency_score += 10
        
        # è¯„çº§
        if efficiency_score >= 80:
            return "ä¼˜ç§€"
        elif efficiency_score >= 60:
            return "è‰¯å¥½"
        elif efficiency_score >= 40:
            return "ä¸€èˆ¬"
        else:
            return "éœ€æ”¹è¿›"
    
    def _update_average(self, current_avg: float, new_value: float, count: int) -> float:
        """æ›´æ–°å¹³å‡å€¼"""
        if count <= 1:
            return new_value
        return round((current_avg * (count - 1) + new_value) / count, 3)
    
    def _generate_ai_programming_report(self, enhanced_logs: List[Dict], ai_stats: Dict, date_range: str) -> str:
        """ç”ŸæˆAIç¼–ç¨‹æ•ˆæœæŠ¥å‘Š"""
        if not enhanced_logs:
            return "ğŸ“­ æš‚æ— AIç¼–ç¨‹æ•°æ®"
        
        # åŸºç¡€ç»Ÿè®¡
        total_sessions = len(enhanced_logs)
        total_lines = sum(log['ai_metrics']['lines_generated'] for log in enhanced_logs)
        total_files = sum(log['ai_metrics']['files_modified'] for log in enhanced_logs)
        
        # å¹³å‡æŒ‡æ ‡
        avg_ai_probability = sum(log['ai_metrics']['ai_probability'] for log in enhanced_logs) / total_sessions
        avg_quality_score = sum(log['ai_metrics']['quality_score'] for log in enhanced_logs) / total_sessions
        avg_productivity = sum(log['ai_metrics']['productivity_score'] for log in enhanced_logs) / total_sessions
        
        # æ•ˆç‡åˆ†å¸ƒ
        efficiency_ratings = [log['ai_metrics']['efficiency_rating'] for log in enhanced_logs]
        rating_counts = {}
        for rating in efficiency_ratings:
            rating_counts[rating] = rating_counts.get(rating, 0) + 1
        
        # ä»£ç è´¨é‡åˆ†æ
        quality_indicators = {
            'with_comments': sum(1 for log in enhanced_logs if log['ai_metrics']['has_comments']),
            'with_error_handling': sum(1 for log in enhanced_logs if log['ai_metrics']['has_error_handling']),
            'with_type_annotations': sum(1 for log in enhanced_logs if log['ai_metrics']['has_type_annotations'])
        }
        
        # å·¥å…·ä½¿ç”¨åˆ†å¸ƒ
        tool_usage = {}
        for log in enhanced_logs:
            tool = log['tool_name']
            tool_usage[tool] = tool_usage.get(tool, 0) + 1
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
ğŸ“ˆ åŸºç¡€æŒ‡æ ‡
  â€¢ ç¼–ç¨‹ä¼šè¯æ€»æ•°ï¼š{total_sessions} æ¬¡
  â€¢ ä»£ç è¡Œæ•°ç”Ÿæˆï¼š{total_lines} è¡Œ
  â€¢ æ–‡ä»¶ä¿®æ”¹æ€»æ•°ï¼š{total_files} ä¸ª
  â€¢ å¹³å‡ä¼šè¯æ—¶é•¿ï¼š{sum(log['ai_metrics']['session_duration'] for log in enhanced_logs) / total_sessions:.1f} åˆ†é’Ÿ

ğŸ¯ AIä½¿ç”¨æ•ˆæœ
  â€¢ AIè¾…åŠ©æ¦‚ç‡ï¼š{avg_ai_probability:.1%}
  â€¢ ä»£ç è´¨é‡åˆ†æ•°ï¼š{avg_quality_score:.1f}/100
  â€¢ ç”Ÿäº§åŠ›è¯„åˆ†ï¼š{avg_productivity:.2f}/1.0

ğŸ’¡ ä»£ç è´¨é‡åˆ†æ
  â€¢ åŒ…å«æ³¨é‡Šï¼š{quality_indicators['with_comments']}/{total_sessions} ({quality_indicators['with_comments']/total_sessions:.1%})
  â€¢ é”™è¯¯å¤„ç†ï¼š{quality_indicators['with_error_handling']}/{total_sessions} ({quality_indicators['with_error_handling']/total_sessions:.1%})
  â€¢ ç±»å‹æ³¨è§£ï¼š{quality_indicators['with_type_annotations']}/{total_sessions} ({quality_indicators['with_type_annotations']/total_sessions:.1%})

âš¡ æ•ˆç‡è¯„çº§åˆ†å¸ƒ
"""
        
        for rating, count in rating_counts.items():
            percentage = count / total_sessions
            report += f"  â€¢ {rating}ï¼š{count} æ¬¡ ({percentage:.1%})\n"
        
        report += f"""
ğŸ› ï¸ å·¥å…·ä½¿ç”¨åˆ†å¸ƒ
"""
        
        for tool, count in sorted(tool_usage.items(), key=lambda x: x[1], reverse=True):
            percentage = count / total_sessions
            report += f"  â€¢ {tool}ï¼š{count} æ¬¡ ({percentage:.1%})\n"
        
        # æ·»åŠ æ”¹è¿›å»ºè®®
        suggestions = self._generate_ai_programming_suggestions(enhanced_logs, avg_quality_score, avg_ai_probability)
        if suggestions:
            report += f"""
ğŸ’¡ æ”¹è¿›å»ºè®®
{suggestions}
"""
        
        return report
    
    def _generate_ai_programming_suggestions(self, enhanced_logs: List[Dict], avg_quality: float, avg_ai_prob: float) -> str:
        """ç”ŸæˆAIç¼–ç¨‹æ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # ä»£ç è´¨é‡å»ºè®®
        if avg_quality < 60:
            suggestions.append("  â€¢ å»ºè®®å¢åŠ ä»£ç æ³¨é‡Šå’Œé”™è¯¯å¤„ç†ï¼Œæé«˜ä»£ç è´¨é‡")
        
        # AIä½¿ç”¨å»ºè®®
        if avg_ai_prob > 0.8:
            suggestions.append("  â€¢ AIä¾èµ–åº¦è¾ƒé«˜ï¼Œå»ºè®®é€‚å½“å¢åŠ æ‰‹å·¥ç¼–ç ç»ƒä¹ ")
        elif avg_ai_prob < 0.3:
            suggestions.append("  â€¢ AIä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥å°è¯•æ›´å¤šAIè¾…åŠ©åŠŸèƒ½")
        
        # æ•ˆç‡å»ºè®®
        low_productivity_sessions = [log for log in enhanced_logs if log['ai_metrics']['productivity_score'] < 0.3]
        if len(low_productivity_sessions) > len(enhanced_logs) * 0.3:
            suggestions.append("  â€¢ éƒ¨åˆ†ä¼šè¯ç”Ÿäº§åŠ›è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–å¼€å‘æµç¨‹")
        
        # å¤æ‚åº¦å»ºè®®
        high_complexity_sessions = [log for log in enhanced_logs if log['ai_metrics']['complexity_added'] > 20]
        if high_complexity_sessions:
            suggestions.append("  â€¢ æ³¨æ„æ§åˆ¶ä»£ç å¤æ‚åº¦ï¼Œè€ƒè™‘é‡æ„å¤æ‚çš„ä»£ç å—")
        
        return "\n".join(suggestions) if suggestions else "  â€¢ å½“å‰å¼€å‘æ•ˆæœè‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼" 